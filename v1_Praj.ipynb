{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so set the device to GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))  # Print the name of the GPU device\n",
    "else:\n",
    "    # CUDA is not available, so set the device to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import datasets\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"roneneldan/TinyStories\")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text\n",
       " 0  One day, a little girl named Lily found a need...\n",
       " 1  Once upon a time, there was a little car named...\n",
       " 2  One day, a little fish named Fin was swimming ...\n",
       " 3  Once upon a time, in a land full of trees, the...\n",
       " 4  Once upon a time, there was a little girl name...,\n",
       "                                                 text\n",
       " 0  Spot. Spot saw the shiny car and said, \"Wow, K...\n",
       " 1  Once upon a time, in a big forest, there lived...\n",
       " 2  Once upon a time, in a small yard, there was a...\n",
       " 3  Once upon a time, there was a thoughtful girl ...\n",
       " 4  Once upon a time, there was a kind farmer. He ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_df = pd.DataFrame(train_dataset['text'])\n",
    "all_val_df = pd.DataFrame(val_dataset['text'])\n",
    "\n",
    "all_train_df.columns = ['text']\n",
    "all_val_df.columns = ['text']\n",
    "\n",
    "\n",
    "all_train_df.head(), all_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One day, a little girl named Lily found a need...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  One day, a little girl named Lily found a need..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = all_train_df[:1]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs_and_labels(df, sp):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        tokens = text.split()  # Tokenize the text by splitting on whitespace\n",
    "\n",
    "        # Generate input by adding start of sentence token at the beginning\n",
    "        input_sequence = tokens\n",
    "\n",
    "        # Generate label by adding end of sentence token at the end\n",
    "        label_sequence = tokens\n",
    "\n",
    "        inputs.append(input_sequence)\n",
    "        labels.append(label_sequence)\n",
    "\n",
    "    # Convert input and label sequences to strings\n",
    "    input_strings = [' '.join(sequence) for sequence in inputs]\n",
    "    label_strings = [' '.join(sequence) for sequence in labels]\n",
    "\n",
    "    # Tokenize input strings and add <sos> token at the beginning\n",
    "    tokenized_inputs = []\n",
    "    input_ids = []\n",
    "    for sequence in input_strings:\n",
    "        tokenized_sequence = sp.encode_as_pieces(sequence)\n",
    "        tokenized_sequence = ['<sos>'] + tokenized_sequence  # Add <sos> token manually\n",
    "        input_ids.append([sp.piece_to_id('<sos>')] + sp.encode_as_ids(sequence))  # Get token IDs\n",
    "        tokenized_inputs.append(tokenized_sequence)\n",
    "\n",
    "    # Tokenize label strings and add </sos> token at the end\n",
    "    tokenized_labels = []\n",
    "    label_ids = []\n",
    "    for sequence in label_strings:\n",
    "        tokenized_sequence = sp.encode_as_pieces(sequence)\n",
    "        tokenized_sequence.append('</sos>')  # Add </sos> token manually at the end\n",
    "        label_ids.append(sp.encode_as_ids(sequence) + [sp.piece_to_id('</sos>')])  # Get token IDs\n",
    "        tokenized_labels.append(tokenized_sequence)\n",
    "\n",
    "    # Print tokenized input and label sequences\n",
    "    for i in range(len(inputs)):\n",
    "        print(\"Input Text:\", input_strings[i])\n",
    "        print(\"Tokenized Input:\", tokenized_inputs[i])\n",
    "        print(\"Input IDs:\", input_ids[i])\n",
    "        print(\"\\n\")\n",
    "        print(\"Label Text:\", label_strings[i])\n",
    "        print(\"Tokenized Label:\", tokenized_labels[i])\n",
    "        print(\"Label IDs:\", label_ids[i])\n",
    "        print(\"---------------------\")\n",
    "\n",
    "    return input_ids, label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt. Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\" Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n",
      "Tokenized Input: ['<sos>', '▁one', '▁day', ',', '▁a', '▁little', '▁girl', '▁name', 'd', '▁lily', '▁found', '▁a', '▁needle', '▁in', '▁her', '▁room', '.', '▁she', '▁knew', '▁it', '▁was', '▁difficult', '▁to', '▁play', '▁with', '▁it', '▁', 'because', '▁it', '▁was', '▁sharp', '.', '▁lily', '▁wanted', '▁to', '▁share', '▁the', '▁needle', '▁with', '▁her', '▁mom', ',', '▁so', '▁she', '▁could', '▁sew', '▁a', '▁button', '▁on', '▁her', '▁shirt', '.', '▁lily', '▁went', '▁to', '▁her', '▁mom', '▁and', '▁said', ',', '▁\"', 'mom', ',', '▁i', '▁found', '▁this', '▁needle', '.', '▁can', '▁you', '▁share', '▁it', '▁with', '▁me', '▁and', '▁sew', '▁my', '▁shirt', '?\"', '▁her', '▁mom', '▁smiled', '▁and', '▁said', ',', '▁\"', 'yes', ',', '▁lily', ',', '▁we', '▁can', '▁share', '▁the', '▁needle', '▁and', '▁fix', '▁your', '▁shirt', '.\"', '▁together', ',', '▁they', '▁shared', '▁the', '▁needle', '▁and', '▁sew', 'ed', '▁the', '▁button', '▁on', '▁lily', \"'\", 's', '▁shirt', '.', '▁it', '▁was', '▁not', '▁difficult', '▁for', '▁them', '▁', 'because', '▁they', '▁were', '▁sharing', '▁and', '▁helping', '▁each', '▁other', '.', '▁after', '▁they', '▁finished', ',', '▁lily', '▁thank', 'ed', '▁her', '▁mom', '▁for', '▁sharing', '▁the', '▁needle', '▁and', '▁fix', 'ing', '▁her', '▁shirt', '.', '▁they', '▁both', '▁felt', '▁happy', '▁', 'because', '▁they', '▁had', '▁shared', '▁and', '▁worked', '▁together', '.']\n",
      "Input IDs: [0, 38, 28, 6, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8, 1293, 32, 14, 802, 3, 31, 68, 7, 14, 43, 5, 18, 6, 16, 749, 6, 49, 119, 149, 1614, 3, 66, 25, 259, 12, 24, 145, 5, 2599, 140, 802, 82, 14, 43, 76, 5, 18, 6, 16, 257, 6, 31, 6, 96, 66, 259, 4, 1614, 5, 524, 129, 802, 46, 104, 6, 13, 678, 4, 1614, 5, 2599, 20, 4, 1293, 32, 31, 17, 15, 802, 3, 12, 9, 60, 1455, 36, 64, 19, 230, 13, 50, 1901, 5, 820, 183, 125, 3, 167, 13, 589, 6, 31, 146, 20, 14, 43, 36, 1901, 4, 1614, 5, 524, 55, 14, 802, 3, 13, 261, 90, 44, 19, 230, 13, 29, 678, 5, 521, 104, 3]\n",
      "\n",
      "\n",
      "Label Text: One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt. Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\" Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n",
      "Tokenized Label: ['▁one', '▁day', ',', '▁a', '▁little', '▁girl', '▁name', 'd', '▁lily', '▁found', '▁a', '▁needle', '▁in', '▁her', '▁room', '.', '▁she', '▁knew', '▁it', '▁was', '▁difficult', '▁to', '▁play', '▁with', '▁it', '▁', 'because', '▁it', '▁was', '▁sharp', '.', '▁lily', '▁wanted', '▁to', '▁share', '▁the', '▁needle', '▁with', '▁her', '▁mom', ',', '▁so', '▁she', '▁could', '▁sew', '▁a', '▁button', '▁on', '▁her', '▁shirt', '.', '▁lily', '▁went', '▁to', '▁her', '▁mom', '▁and', '▁said', ',', '▁\"', 'mom', ',', '▁i', '▁found', '▁this', '▁needle', '.', '▁can', '▁you', '▁share', '▁it', '▁with', '▁me', '▁and', '▁sew', '▁my', '▁shirt', '?\"', '▁her', '▁mom', '▁smiled', '▁and', '▁said', ',', '▁\"', 'yes', ',', '▁lily', ',', '▁we', '▁can', '▁share', '▁the', '▁needle', '▁and', '▁fix', '▁your', '▁shirt', '.\"', '▁together', ',', '▁they', '▁shared', '▁the', '▁needle', '▁and', '▁sew', 'ed', '▁the', '▁button', '▁on', '▁lily', \"'\", 's', '▁shirt', '.', '▁it', '▁was', '▁not', '▁difficult', '▁for', '▁them', '▁', 'because', '▁they', '▁were', '▁sharing', '▁and', '▁helping', '▁each', '▁other', '.', '▁after', '▁they', '▁finished', ',', '▁lily', '▁thank', 'ed', '▁her', '▁mom', '▁for', '▁sharing', '▁the', '▁needle', '▁and', '▁fix', 'ing', '▁her', '▁shirt', '.', '▁they', '▁both', '▁felt', '▁happy', '▁', 'because', '▁they', '▁had', '▁shared', '▁and', '▁worked', '▁together', '.', '</sos>']\n",
      "Label IDs: [38, 28, 6, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8, 1293, 32, 14, 802, 3, 31, 68, 7, 14, 43, 5, 18, 6, 16, 749, 6, 49, 119, 149, 1614, 3, 66, 25, 259, 12, 24, 145, 5, 2599, 140, 802, 82, 14, 43, 76, 5, 18, 6, 16, 257, 6, 31, 6, 96, 66, 259, 4, 1614, 5, 524, 129, 802, 46, 104, 6, 13, 678, 4, 1614, 5, 2599, 20, 4, 1293, 32, 31, 17, 15, 802, 3, 12, 9, 60, 1455, 36, 64, 19, 230, 13, 50, 1901, 5, 820, 183, 125, 3, 167, 13, 589, 6, 31, 146, 20, 14, 43, 36, 1901, 4, 1614, 5, 524, 55, 14, 802, 3, 13, 261, 90, 44, 19, 230, 13, 29, 678, 5, 521, 104, 3, 0]\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('small_m.model')\n",
    "\n",
    "source_ids, target_ids = generate_inputs_and_labels(train_df, sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "\n",
    "############################################################################\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.max_seq_length = max_seq_length\n",
    "        pe = self._init_pe(max_seq_length, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_length = x.size(1)\n",
    "        pe = self.pe[:seq_length, :] if seq_length <= self.max_seq_length else self._init_pe(seq_length, self.d_model)\n",
    "        return x + pe\n",
    "\n",
    "    def _init_pe(self, seq_length, d_model):\n",
    "        pe = torch.zeros(seq_length, d_model)\n",
    "        position = torch.arange(0, seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        return pe\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, decoder_input, decoder_mask):\n",
    "        attn_output = self.self_attn(decoder_input, decoder_input, decoder_input, decoder_mask)\n",
    "        x = self.norm1(decoder_input + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, tgt):\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return tgt_mask\n",
    "\n",
    "    def forward(self, decoder_input):\n",
    "        decoder_mask = self.generate_mask(decoder_input)\n",
    "        decoder_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(decoder_input)))\n",
    "\n",
    "        dec_output = decoder_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, decoder_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data shape: torch.Size([1, 165])\n",
      "Target data shape: torch.Size([1, 165])\n",
      "tensor([[   0,   38,   28,    6,    8,   37,   53,   86,   34,   31,  119,    8,\n",
      "         1614,   21,   14,  198,    3,   11,  185,   12,    9, 1455,    7,   54,\n",
      "           24,   12,   19,  230,   12,    9, 1316,    3,   31,   59,    7,  259,\n",
      "            4, 1614,   24,   14,   43,    6,   23,   11,   94, 2599,    8, 1293,\n",
      "           32,   14,  802,    3,   31,   68,    7,   14,   43,    5,   18,    6,\n",
      "           16,  749,    6,   49,  119,  149, 1614,    3,   66,   25,  259,   12,\n",
      "           24,  145,    5, 2599,  140,  802,   82,   14,   43,   76,    5,   18,\n",
      "            6,   16,  257,    6,   31,    6,   96,   66,  259,    4, 1614,    5,\n",
      "          524,  129,  802,   46,  104,    6,   13,  678,    4, 1614,    5, 2599,\n",
      "           20,    4, 1293,   32,   31,   17,   15,  802,    3,   12,    9,   60,\n",
      "         1455,   36,   64,   19,  230,   13,   50, 1901,    5,  820,  183,  125,\n",
      "            3,  167,   13,  589,    6,   31,  146,   20,   14,   43,   36, 1901,\n",
      "            4, 1614,    5,  524,   55,   14,  802,    3,   13,  261,   90,   44,\n",
      "           19,  230,   13,   29,  678,    5,  521,  104,    3]])\n",
      "tensor([[  38,   28,    6,    8,   37,   53,   86,   34,   31,  119,    8, 1614,\n",
      "           21,   14,  198,    3,   11,  185,   12,    9, 1455,    7,   54,   24,\n",
      "           12,   19,  230,   12,    9, 1316,    3,   31,   59,    7,  259,    4,\n",
      "         1614,   24,   14,   43,    6,   23,   11,   94, 2599,    8, 1293,   32,\n",
      "           14,  802,    3,   31,   68,    7,   14,   43,    5,   18,    6,   16,\n",
      "          749,    6,   49,  119,  149, 1614,    3,   66,   25,  259,   12,   24,\n",
      "          145,    5, 2599,  140,  802,   82,   14,   43,   76,    5,   18,    6,\n",
      "           16,  257,    6,   31,    6,   96,   66,  259,    4, 1614,    5,  524,\n",
      "          129,  802,   46,  104,    6,   13,  678,    4, 1614,    5, 2599,   20,\n",
      "            4, 1293,   32,   31,   17,   15,  802,    3,   12,    9,   60, 1455,\n",
      "           36,   64,   19,  230,   13,   50, 1901,    5,  820,  183,  125,    3,\n",
      "          167,   13,  589,    6,   31,  146,   20,   14,   43,   36, 1901,    4,\n",
      "         1614,    5,  524,   55,   14,  802,    3,   13,  261,   90,   44,   19,\n",
      "          230,   13,   29,  678,    5,  521,  104,    3,    0]])\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to tensors\n",
    "source_data = torch.tensor(source_ids)\n",
    "target_data = torch.tensor(target_ids)\n",
    "\n",
    "# Print shapes\n",
    "print(\"Source data shape:\", source_data.shape)\n",
    "print(\"Target data shape:\", target_data.shape)\n",
    "\n",
    "print(source_data)\n",
    "print(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 8.728713989257812\n",
      "Epoch: 11, Loss: 0.79233717918396\n",
      "Epoch: 21, Loss: 0.09561437368392944\n",
      "Epoch: 31, Loss: 0.016201868653297424\n",
      "Epoch: 41, Loss: 0.005629836115986109\n",
      "Epoch: 51, Loss: 0.0034210735466331244\n",
      "Epoch: 61, Loss: 0.0017595504177734256\n",
      "Epoch: 71, Loss: 0.0013070730492472649\n",
      "Epoch: 81, Loss: 0.0010462588397786021\n",
      "Epoch: 91, Loss: 0.000880131614394486\n",
      "Epoch: 101, Loss: 0.0008216156857088208\n",
      "Epoch: 111, Loss: 0.0007101529627107084\n",
      "Epoch: 121, Loss: 0.0006273101316764951\n",
      "Epoch: 131, Loss: 0.0005985501338727772\n",
      "Epoch: 141, Loss: 0.0005261104088276625\n",
      "Epoch: 151, Loss: 0.00047058743075467646\n",
      "Epoch: 161, Loss: 0.00043098125024698675\n",
      "Epoch: 171, Loss: 0.00039283098885789514\n",
      "Epoch: 181, Loss: 0.0003671552403829992\n",
      "Epoch: 191, Loss: 0.00034166150726377964\n",
      "Epoch: 201, Loss: 0.00030909106135368347\n",
      "Epoch: 211, Loss: 0.00028689816826954484\n",
      "Epoch: 221, Loss: 0.0002626240602694452\n",
      "Epoch: 231, Loss: 0.00023609347408637404\n",
      "Epoch: 241, Loss: 0.00021129203378222883\n",
      "Epoch: 251, Loss: 0.00019762733427342027\n",
      "Epoch: 261, Loss: 0.00018020800780504942\n",
      "Epoch: 271, Loss: 0.0001747456844896078\n",
      "Epoch: 281, Loss: 0.00015910975344013423\n",
      "Epoch: 291, Loss: 0.00014200348232407123\n",
      "Epoch: 301, Loss: 0.00013975186448078603\n",
      "Epoch: 311, Loss: 0.00011939503019675612\n",
      "Epoch: 321, Loss: 0.07216396927833557\n",
      "Epoch: 331, Loss: 0.025724725797772408\n",
      "Epoch: 341, Loss: 0.004545265343040228\n",
      "Epoch: 351, Loss: 0.16113685071468353\n",
      "Epoch: 361, Loss: 0.003308309940621257\n",
      "Epoch: 371, Loss: 0.01932286098599434\n",
      "Epoch: 381, Loss: 0.00758114829659462\n",
      "Epoch: 391, Loss: 0.03701712563633919\n",
      "Epoch: 401, Loss: 0.01587388664484024\n",
      "Epoch: 411, Loss: 0.027331983670592308\n",
      "Epoch: 421, Loss: 0.04340016096830368\n",
      "Epoch: 431, Loss: 0.005490096285939217\n",
      "Epoch: 441, Loss: 0.03969529643654823\n",
      "Epoch: 451, Loss: 0.0011710026301443577\n",
      "Epoch: 461, Loss: 0.011997787281870842\n",
      "Epoch: 471, Loss: 0.0023692231625318527\n",
      "Epoch: 481, Loss: 0.0004559033550322056\n",
      "Epoch: 491, Loss: 0.00019683838763739914\n",
      "Epoch: 501, Loss: 0.038073379546403885\n",
      "Epoch: 511, Loss: 0.01567695289850235\n",
      "Epoch: 521, Loss: 0.06240054592490196\n",
      "Epoch: 531, Loss: 0.02855837345123291\n",
      "Epoch: 541, Loss: 0.009435554966330528\n",
      "Epoch: 551, Loss: 0.006829060614109039\n",
      "Epoch: 561, Loss: 0.0024896732065826654\n",
      "Epoch: 571, Loss: 0.0013030872214585543\n",
      "Epoch: 581, Loss: 0.09136967360973358\n",
      "Epoch: 591, Loss: 0.026382286101579666\n",
      "Epoch: 601, Loss: 0.0372907929122448\n",
      "Epoch: 611, Loss: 0.022652998566627502\n",
      "Epoch: 621, Loss: 0.004591382574290037\n",
      "Epoch: 631, Loss: 0.0011461084941402078\n",
      "Epoch: 641, Loss: 0.00032711500534787774\n",
      "Epoch: 651, Loss: 0.00012749199231620878\n",
      "Epoch: 661, Loss: 0.001327306148596108\n",
      "Epoch: 671, Loss: 0.000162452386575751\n",
      "Epoch: 681, Loss: 0.00034543927176855505\n",
      "Epoch: 691, Loss: 0.00010957725316984579\n",
      "Epoch: 701, Loss: 0.00012022382725263014\n",
      "Epoch: 711, Loss: 6.571038102265447e-05\n",
      "Epoch: 721, Loss: 2.789976315398235e-05\n",
      "Epoch: 731, Loss: 2.7929923817282543e-05\n",
      "Epoch: 741, Loss: 2.302764551131986e-05\n",
      "Epoch: 751, Loss: 2.0488902009674348e-05\n",
      "Epoch: 761, Loss: 1.7621343431528658e-05\n",
      "Epoch: 771, Loss: 1.4476457181444857e-05\n",
      "Epoch: 781, Loss: 1.704202986729797e-05\n",
      "Epoch: 791, Loss: 1.564647573104594e-05\n",
      "Epoch: 801, Loss: 1.3130278603057377e-05\n",
      "Epoch: 811, Loss: 1.1185191397089511e-05\n",
      "Epoch: 821, Loss: 1.030568455462344e-05\n",
      "Epoch: 831, Loss: 9.77722265815828e-06\n",
      "Epoch: 841, Loss: 1.7263597328565083e-05\n",
      "Epoch: 851, Loss: 9.074356967175845e-06\n",
      "Epoch: 861, Loss: 8.233976586780045e-06\n",
      "Epoch: 871, Loss: 6.950433999008965e-06\n",
      "Epoch: 881, Loss: 7.798678780090995e-06\n",
      "Epoch: 891, Loss: 7.797202670190018e-06\n",
      "Epoch: 901, Loss: 5.855015388078755e-06\n",
      "Epoch: 911, Loss: 5.605714250123128e-06\n",
      "Epoch: 921, Loss: 1.2806401173293125e-05\n",
      "Epoch: 931, Loss: 4.862843525188509e-06\n",
      "Epoch: 941, Loss: 4.700022145698313e-06\n",
      "Epoch: 951, Loss: 4.069091573910555e-06\n",
      "Epoch: 961, Loss: 3.4926761145470664e-06\n",
      "Epoch: 971, Loss: 4.023293968202779e-06\n",
      "Epoch: 981, Loss: 3.6554965845425613e-06\n",
      "Epoch: 991, Loss: 3.243352921344922e-06\n"
     ]
    }
   ],
   "source": [
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 512\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "transformer = Transformer( tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "lossess = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(source_data)\n",
    "    \n",
    "    # Adjust target_data to have the same length as model output\n",
    "    target_data_adjusted = target_data[:, :output.size(1)]\n",
    "    \n",
    "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), target_data_adjusted.contiguous().view(-1))\n",
    "    lossess.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10==0 or epoch == 0 or epoch == epochs:\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (decoder_embedding): Embedding(5000, 512)\n",
      "  (positional_encoding): PositionalEncoding()\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0-5): 6 x DecoderLayer(\n",
      "      (self_attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (feed_forward): PositionWiseFeedForward(\n",
      "        (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=5000, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming lossess is a list of PyTorch tensors\n",
    "lossess = [l.detach().numpy() for l in lossess]  # Convert each tensor to NumPy array\n",
    "epochs = [i for i, _ in enumerate(lossess)]  # Create epochs list\n",
    "\n",
    "# Configure the plot\n",
    "plt.figure(figsize=(8, 5))  # Set the plot size\n",
    "plt.plot(epochs, lossess, marker='o', linestyle='-')  # Plot the data with markers and line\n",
    "plt.xlabel('Epochs')  # Label the x-axis\n",
    "plt.ylabel('Loss')  # Label the y-axis\n",
    "plt.title('Training Loss')  # Set a title for the plot\n",
    "plt.grid(True)  # Add a grid for better readability\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_token is 8\n",
      "generated_sequence is [2255, 8]\n",
      "-------\n",
      "predicted_token is 37\n",
      "generated_sequence is [2255, 8, 37]\n",
      "-------\n",
      "predicted_token is 53\n",
      "generated_sequence is [2255, 8, 37, 53]\n",
      "-------\n",
      "predicted_token is 86\n",
      "generated_sequence is [2255, 8, 37, 53, 86]\n",
      "-------\n",
      "predicted_token is 34\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34]\n",
      "-------\n",
      "predicted_token is 31\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31]\n",
      "-------\n",
      "predicted_token is 119\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119]\n",
      "-------\n",
      "predicted_token is 8\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8]\n",
      "-------\n",
      "predicted_token is 1614\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614]\n",
      "-------\n",
      "predicted_token is 21\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21]\n",
      "-------\n",
      "predicted_token is 14\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14]\n",
      "-------\n",
      "predicted_token is 198\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198]\n",
      "-------\n",
      "predicted_token is 3\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3]\n",
      "-------\n",
      "predicted_token is 11\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11]\n",
      "-------\n",
      "predicted_token is 185\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185]\n",
      "-------\n",
      "predicted_token is 12\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12]\n",
      "-------\n",
      "predicted_token is 9\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9]\n",
      "-------\n",
      "predicted_token is 1455\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455]\n",
      "-------\n",
      "predicted_token is 7\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7]\n",
      "-------\n",
      "predicted_token is 54\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54]\n",
      "-------\n",
      "predicted_token is 24\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24]\n",
      "-------\n",
      "predicted_token is 7\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7]\n",
      "-------\n",
      "predicted_token is 54\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54]\n",
      "-------\n",
      "predicted_token is 24\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24]\n",
      "-------\n",
      "predicted_token is 12\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12]\n",
      "-------\n",
      "predicted_token is 19\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19]\n",
      "-------\n",
      "predicted_token is 230\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230]\n",
      "-------\n",
      "predicted_token is 12\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12]\n",
      "-------\n",
      "predicted_token is 9\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9]\n",
      "-------\n",
      "predicted_token is 1316\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316]\n",
      "-------\n",
      "predicted_token is 3\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3]\n",
      "-------\n",
      "predicted_token is 31\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31]\n",
      "-------\n",
      "predicted_token is 59\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59]\n",
      "-------\n",
      "predicted_token is 7\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7]\n",
      "-------\n",
      "predicted_token is 259\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259]\n",
      "-------\n",
      "predicted_token is 4\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4]\n",
      "-------\n",
      "predicted_token is 1614\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614]\n",
      "-------\n",
      "predicted_token is 24\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24]\n",
      "-------\n",
      "predicted_token is 14\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14]\n",
      "-------\n",
      "predicted_token is 43\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43]\n",
      "-------\n",
      "predicted_token is 6\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6]\n",
      "-------\n",
      "predicted_token is 23\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23]\n",
      "-------\n",
      "predicted_token is 11\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11]\n",
      "-------\n",
      "predicted_token is 94\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94]\n",
      "-------\n",
      "predicted_token is 2599\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599]\n",
      "-------\n",
      "predicted_token is 8\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8]\n",
      "-------\n",
      "predicted_token is 1293\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8, 1293]\n",
      "-------\n",
      "predicted_token is 32\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8, 1293, 32]\n",
      "-------\n",
      "predicted_token is 14\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8, 1293, 32, 14]\n",
      "-------\n",
      "predicted_token is 802\n",
      "generated_sequence is [2255, 8, 37, 53, 86, 34, 31, 119, 8, 1614, 21, 14, 198, 3, 11, 185, 12, 9, 1455, 7, 54, 24, 7, 54, 24, 12, 19, 230, 12, 9, 1316, 3, 31, 59, 7, 259, 4, 1614, 24, 14, 43, 6, 23, 11, 94, 2599, 8, 1293, 32, 14, 802]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "def word_to_token_id(word, sp_model):\n",
    "    # Convert word to token ID using SentencePiece\n",
    "    return sp_model.piece_to_id(word)\n",
    "\n",
    "def generate_text(model, sp_model, starting_word, ending_word, max_length):\n",
    "    # Convert starting and ending words to token IDs\n",
    "    starting_token_id = word_to_token_id(starting_word, sp_model)\n",
    "    if starting_token_id is None:\n",
    "        raise ValueError(f\"Starting word '{starting_word}' not found in vocabulary.\")\n",
    "    ending_token_id = word_to_token_id(ending_word, sp_model)\n",
    "    if ending_token_id is None:\n",
    "        raise ValueError(f\"Ending word '{ending_word}' not found in vocabulary.\")\n",
    "    \n",
    "    generated_sequence = [starting_token_id]\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            input_tensor = torch.tensor([generated_sequence])\n",
    "            output = model(input_tensor)\n",
    "            predicted_token = output.argmax(-1)[:,-1].item()\n",
    "            print(f\"predicted_token is {predicted_token}\")\n",
    "\n",
    "            generated_sequence.append(predicted_token)\n",
    "            print(f\"generated_sequence is {generated_sequence}\")\n",
    "            if predicted_token == ending_token_id:\n",
    "                break\n",
    "            print(\"-------\")\n",
    "    \n",
    "    # Convert token IDs to words using SentencePiece\n",
    "    generated_text = sp_model.decode_ids(generated_sequence)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "starting_word = \"she\"\n",
    "ending_word = \"</sos>\"\n",
    "max_length = 50\n",
    "generated_sequence = generate_text(transformer, sp, starting_word, ending_word, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: she a little girl named lily found a needle in her room. she knew it was difficult to play with to play with it because it was sharp. lily wanted to share the needle with her mom, so she could sew a button on her shirt\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated sequence:\", generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ntgt_vocab_size = 5000\\nd_model = 64\\nnum_heads = 8\\nnum_layers = 6\\nd_ff = 512\\nmax_seq_length = 100\\ndropout = 0.1\\nepochs = 100\\nstarting_word = \"lily\"\\nending_word = \"</sos>\"\\nmax_length = 50\\n\\n\\nlily. can you share it was difficult to share the needle with her mom and sew my shirt. \\nlily wanted to play with it because it was sharp. lily wanted to share the needle with \\nher mom, so she could sew a button on her shirt\\n\\n\\ntgt_vocab_size = 5000\\nd_model = 512 (8 times more embeddings)\\nnum_heads = 8\\nnum_layers = 6\\nd_ff = 512\\nmax_seq_length = 100\\ndropout = 0.1\\nepochs = 1000 (10 times more epochs)\\nstarting_word = \"lily\"\\nending_word = \"</sos>\"\\nmax_length = 50\\n\\n\\nlily in her room. she could sew a little girl named lily found a needle in her mom for sharing play \\nwith it because it was sharp. lily wanted to her mom for sharing the needle with her mom, so she could sew a button on\\n\\n# After 300 epochs, the model isnt learning much, and the difference is incomparable\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 64\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 512\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "epochs = 100\n",
    "starting_word = \"lily\"\n",
    "ending_word = \"</sos>\"\n",
    "max_length = 50\n",
    "\n",
    "\n",
    "lily. can you share it was difficult to share the needle with her mom and sew my shirt. \n",
    "lily wanted to play with it because it was sharp. lily wanted to share the needle with \n",
    "her mom, so she could sew a button on her shirt\n",
    "\n",
    "\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512 (8 times more embeddings)\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 512\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "epochs = 1000 (10 times more epochs)\n",
    "starting_word = \"lily\"\n",
    "ending_word = \"</sos>\"\n",
    "max_length = 50\n",
    "\n",
    "\n",
    "lily in her room. she could sew a little girl named lily found a needle in her mom for sharing play \n",
    "with it because it was sharp. lily wanted to her mom for sharing the needle with her mom, so she could sew a button on\n",
    "\n",
    "# After 300 epochs, the model isnt learning much, and the difference is incomparable\n",
    "# Time to scale up\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#torch.save(transformer.state_dict(), 'transformer_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
